{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_directory):\n",
    "    sequence = []\n",
    "    files = glob.glob(f\"{input_directory}/*\")\n",
    "    for file in files:\n",
    "        with open(file, \"rt\", encoding=\"utf-8\") as f:\n",
    "            raw_text = f.read()\n",
    "            sequence.append((file, raw_text))\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt It is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt Electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input\\file3.txt Global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "for file, text in sequence:\n",
    "    print(f\"{file} {text[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt it is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input\\file3.txt global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(sequence):\n",
    "    cleaned_sequence = []\n",
    "    for file, text in sequence:\n",
    "        cleaned_text = re.sub(r\"\\n\", \" \", text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "        cleaned_text = cleaned_text.lower()\n",
    "        cleaned_sequence.append((file, cleaned_text))\n",
    "    return cleaned_sequence\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "for file, text in cleaned_sequence:\n",
    "    print(f\"{file} {text[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Crimson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt it is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt electric vehicles are gaining global popularity lately , and along wit\n",
      "../files/input\\file3.txt global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "def tokenize(sequence):\n",
    "    tokenized_sequence = []\n",
    "    for file, text in sequence:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokenized_sequence.append((file, tokens))\n",
    "    return tokenized_sequence\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "for file, text in tokenized_sequence:\n",
    "    print(f\"{file} {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'non-precious',\n",
       " 'metal-based',\n",
       " 'alternatives',\n",
       " 'used',\n",
       " 'in',\n",
       " 'hydrogen',\n",
       " 'evolution',\n",
       " 'reaction',\n",
       " '(',\n",
       " 'her',\n",
       " ')',\n",
       " 'due',\n",
       " 'to',\n",
       " 'high',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'scarcity',\n",
       " 'of',\n",
       " 'pt-based',\n",
       " 'catalysts',\n",
       " '.',\n",
       " 'herein',\n",
       " ',',\n",
       " 'through',\n",
       " 'density',\n",
       " 'functional',\n",
       " 'theory',\n",
       " '(',\n",
       " 'dft',\n",
       " ')',\n",
       " 'calculations',\n",
       " ',',\n",
       " 'the',\n",
       " 'her',\n",
       " 'activity',\n",
       " 'over',\n",
       " '26',\n",
       " 'single-atom',\n",
       " 'anchored',\n",
       " 'phosphorus',\n",
       " 'carbide',\n",
       " '(',\n",
       " 'pc3',\n",
       " ')',\n",
       " 'monolayer',\n",
       " '(',\n",
       " 'tm',\n",
       " '@',\n",
       " 'pc3',\n",
       " ')',\n",
       " 'has',\n",
       " 'been',\n",
       " 'systematically',\n",
       " 'investigated',\n",
       " '.',\n",
       " 'results',\n",
       " 'indicate',\n",
       " 'that',\n",
       " 'δg',\n",
       " '*',\n",
       " 'h',\n",
       " 'of',\n",
       " 'v',\n",
       " ',',\n",
       " 'fe',\n",
       " ',',\n",
       " 'nb',\n",
       " ',',\n",
       " 'mo',\n",
       " ',',\n",
       " 'and',\n",
       " 'pd',\n",
       " '@',\n",
       " 'pc3',\n",
       " 'are',\n",
       " 'lower',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'pt',\n",
       " '(',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " ')',\n",
       " 'catalyst',\n",
       " ',',\n",
       " 'with',\n",
       " '0.03',\n",
       " ',',\n",
       " '−0.03',\n",
       " ',',\n",
       " '−0.07',\n",
       " ',',\n",
       " '−0.04',\n",
       " ',',\n",
       " 'and',\n",
       " '−',\n",
       " '0.02',\n",
       " 'ev',\n",
       " ',',\n",
       " 'respectively',\n",
       " '.',\n",
       " 'by',\n",
       " 'imposing',\n",
       " 'the',\n",
       " 'criterion',\n",
       " 'window',\n",
       " '(',\n",
       " '−0.2',\n",
       " '≤',\n",
       " 'δg',\n",
       " '*',\n",
       " 'h',\n",
       " '≤',\n",
       " '0.2',\n",
       " 'ev',\n",
       " ')',\n",
       " ',',\n",
       " 'the',\n",
       " 'd',\n",
       " 'band',\n",
       " 'centre',\n",
       " '(',\n",
       " 'εd',\n",
       " ')',\n",
       " 'for',\n",
       " 'catalysts',\n",
       " 'with',\n",
       " 'excellent',\n",
       " 'her',\n",
       " 'ability',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'range',\n",
       " 'of',\n",
       " '−',\n",
       " '0.68–0.41',\n",
       " 'ev',\n",
       " '.',\n",
       " 'besides',\n",
       " ',',\n",
       " 'the',\n",
       " 'five',\n",
       " 'promising',\n",
       " 'her',\n",
       " 'catalysts',\n",
       " 'follow',\n",
       " 'volmer-tafel',\n",
       " 'mechanism',\n",
       " '.',\n",
       " 'fe',\n",
       " ',',\n",
       " 'nb',\n",
       " ',',\n",
       " 'and',\n",
       " 'mo',\n",
       " '@',\n",
       " 'pc3',\n",
       " 'show',\n",
       " 'activation',\n",
       " 'barriers',\n",
       " 'of',\n",
       " '0.75',\n",
       " ',',\n",
       " '0.74',\n",
       " ',',\n",
       " 'and',\n",
       " '0.55',\n",
       " 'ev',\n",
       " ',',\n",
       " 'lower',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'pt',\n",
       " '.',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '(',\n",
       " 'ml',\n",
       " ')',\n",
       " 'was',\n",
       " 'employed',\n",
       " 'to',\n",
       " 'explore',\n",
       " 'the',\n",
       " 'intrinsic',\n",
       " 'relationship',\n",
       " 'between',\n",
       " 'catalytic',\n",
       " 'performance',\n",
       " 'and',\n",
       " 'feature',\n",
       " 'parameters',\n",
       " '.',\n",
       " 'we',\n",
       " 'demonstrated',\n",
       " 'that',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ionization',\n",
       " 'energy',\n",
       " ',',\n",
       " 'bond',\n",
       " 'length',\n",
       " 'of',\n",
       " 'tm',\n",
       " '−',\n",
       " 'h',\n",
       " 'and',\n",
       " 'd',\n",
       " 'band',\n",
       " 'center',\n",
       " 'are',\n",
       " 'more',\n",
       " 'correlated',\n",
       " 'with',\n",
       " 'hydrogen',\n",
       " 'adsorption',\n",
       " 'behaviour',\n",
       " '.',\n",
       " 'our',\n",
       " 'work',\n",
       " 'not',\n",
       " 'only',\n",
       " 'predicts',\n",
       " 'that',\n",
       " 'fe',\n",
       " ',',\n",
       " 'nb',\n",
       " ',',\n",
       " 'and',\n",
       " 'mo',\n",
       " '@',\n",
       " 'pc3',\n",
       " 'can',\n",
       " 'be',\n",
       " 'substitutes',\n",
       " 'for',\n",
       " 'pt',\n",
       " 'metal',\n",
       " 'in',\n",
       " 'her',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'reveals',\n",
       " 'that',\n",
       " 'the',\n",
       " 'intrinsic',\n",
       " 'correlation',\n",
       " 'between',\n",
       " 'catalytic',\n",
       " 'activity',\n",
       " 'and',\n",
       " 'feature',\n",
       " 'parameters',\n",
       " 'by',\n",
       " 'combining',\n",
       " 'dft',\n",
       " 'and',\n",
       " 'ml',\n",
       " 'investigations',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sequence[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt it is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt electric vehicles are gaining global popularity lately , and along wit\n",
      "../files/input\\file3.txt global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "def filter_tokens_a(sequence):\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [token for token in tokens if token.isalpha()]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_a(tokenized_sequence)\n",
    "for file, text in tokenized_sequence:\n",
    "    print(f\"{file} {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'alternatives',\n",
       " 'used',\n",
       " 'in',\n",
       " 'hydrogen',\n",
       " 'evolution',\n",
       " 'reaction',\n",
       " 'her',\n",
       " 'due',\n",
       " 'to',\n",
       " 'high',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'scarcity',\n",
       " 'of',\n",
       " 'catalysts',\n",
       " 'herein',\n",
       " 'through',\n",
       " 'density',\n",
       " 'functional',\n",
       " 'theory',\n",
       " 'dft',\n",
       " 'calculations',\n",
       " 'the',\n",
       " 'her',\n",
       " 'activity',\n",
       " 'over',\n",
       " 'anchored',\n",
       " 'phosphorus',\n",
       " 'carbide',\n",
       " 'monolayer',\n",
       " 'tm',\n",
       " 'has',\n",
       " 'been',\n",
       " 'systematically',\n",
       " 'investigated',\n",
       " 'results',\n",
       " 'indicate',\n",
       " 'that',\n",
       " 'δg',\n",
       " 'h',\n",
       " 'of',\n",
       " 'v',\n",
       " 'fe',\n",
       " 'nb',\n",
       " 'mo',\n",
       " 'and',\n",
       " 'pd',\n",
       " 'are',\n",
       " 'lower',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'pt',\n",
       " 'catalyst',\n",
       " 'with',\n",
       " 'and',\n",
       " 'ev',\n",
       " 'respectively',\n",
       " 'by',\n",
       " 'imposing',\n",
       " 'the',\n",
       " 'criterion',\n",
       " 'window',\n",
       " 'δg',\n",
       " 'h',\n",
       " 'ev',\n",
       " 'the',\n",
       " 'd',\n",
       " 'band',\n",
       " 'centre',\n",
       " 'εd',\n",
       " 'for',\n",
       " 'catalysts',\n",
       " 'with',\n",
       " 'excellent',\n",
       " 'her',\n",
       " 'ability',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'range',\n",
       " 'of',\n",
       " 'ev',\n",
       " 'besides',\n",
       " 'the',\n",
       " 'five',\n",
       " 'promising',\n",
       " 'her',\n",
       " 'catalysts',\n",
       " 'follow',\n",
       " 'mechanism',\n",
       " 'fe',\n",
       " 'nb',\n",
       " 'and',\n",
       " 'mo',\n",
       " 'show',\n",
       " 'activation',\n",
       " 'barriers',\n",
       " 'of',\n",
       " 'and',\n",
       " 'ev',\n",
       " 'lower',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'pt',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'ml',\n",
       " 'was',\n",
       " 'employed',\n",
       " 'to',\n",
       " 'explore',\n",
       " 'the',\n",
       " 'intrinsic',\n",
       " 'relationship',\n",
       " 'between',\n",
       " 'catalytic',\n",
       " 'performance',\n",
       " 'and',\n",
       " 'feature',\n",
       " 'parameters',\n",
       " 'we',\n",
       " 'demonstrated',\n",
       " 'that',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ionization',\n",
       " 'energy',\n",
       " 'bond',\n",
       " 'length',\n",
       " 'of',\n",
       " 'tm',\n",
       " 'h',\n",
       " 'and',\n",
       " 'd',\n",
       " 'band',\n",
       " 'center',\n",
       " 'are',\n",
       " 'more',\n",
       " 'correlated',\n",
       " 'with',\n",
       " 'hydrogen',\n",
       " 'adsorption',\n",
       " 'behaviour',\n",
       " 'our',\n",
       " 'work',\n",
       " 'not',\n",
       " 'only',\n",
       " 'predicts',\n",
       " 'that',\n",
       " 'fe',\n",
       " 'nb',\n",
       " 'and',\n",
       " 'mo',\n",
       " 'can',\n",
       " 'be',\n",
       " 'substitutes',\n",
       " 'for',\n",
       " 'pt',\n",
       " 'metal',\n",
       " 'in',\n",
       " 'her',\n",
       " 'but',\n",
       " 'also',\n",
       " 'reveals',\n",
       " 'that',\n",
       " 'the',\n",
       " 'intrinsic',\n",
       " 'correlation',\n",
       " 'between',\n",
       " 'catalytic',\n",
       " 'activity',\n",
       " 'and',\n",
       " 'feature',\n",
       " 'parameters',\n",
       " 'by',\n",
       " 'combining',\n",
       " 'dft',\n",
       " 'and',\n",
       " 'ml',\n",
       " 'investigations']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sequence[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt it is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt electric vehicles are gaining global popularity lately , and along wit\n",
      "../files/input\\file3.txt global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "def filter_tokens_b(sequence):\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [re.sub(r\"[^a-zA-Z\\s]\", \" \", token) for token in tokens]\n",
    "        filtered_tokens = [re.sub(r\"\\s+\", \" \", token) for token in filtered_tokens]\n",
    "        filtered_tokens = [token.strip() for token in filtered_tokens]\n",
    "        filtered_tokens = [token for token in filtered_tokens if token != \"\"]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "for file, text in tokenized_sequence:\n",
    "    print(f\"{file} {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Crimson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt essential develop non precious metal based alternatives used hydrogen \n",
      "../files/input\\file2.txt electric vehicles gaining global popularity lately along efficient bat\n",
      "../files/input\\file3.txt global solar irradiation important variable used determine suitability\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def remove_stopwords(sequence):\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "filtered_sequence = remove_stopwords(filtered_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file} {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'him', \"it's\", 'herself', 'on', 'few', \"didn't\", 'her', 'whom', 'be', \"they've\", 'more', 'wasn', \"mustn't\", 'any', \"she'd\", 'ma', \"needn't\", \"i'll\", 'between', \"shan't\", \"we'll\", 'y', 'haven', 'not', 'is', 'most', \"hasn't\", 'into', 'to', 'yourselves', \"couldn't\", 'them', \"shouldn't\", 'through', 'under', 'very', 'aren', 'ourselves', \"weren't\", 'other', \"we've\", 'during', 't', 'd', 'now', 'own', 'above', 'this', 'me', 'wouldn', 'did', 'up', 'about', 'should', 're', \"i'm\", 'weren', 'because', 'and', 'the', \"it'll\", 'themselves', \"you've\", 'itself', 'll', 'of', 'myself', 'we', 'they', 'won', 'until', 'all', 'shouldn', 'that', \"he'd\", 'from', \"won't\", 'am', 'who', 'in', 'were', 'isn', 'then', 'out', 'only', 'further', \"don't\", \"hadn't\", \"haven't\", 'how', 'o', \"i've\", \"they're\", \"they'd\", 'too', 'didn', 'himself', 'once', 'he', 'if', 'my', \"isn't\", 'by', 'no', 'again', 'can', 'needn', \"wasn't\", 'down', 'after', 'shan', 'it', \"it'd\", 'do', 'such', 'same', 'being', 'she', 'have', 'those', \"wouldn't\", \"aren't\", 'ours', 'mustn', \"you're\", 'his', 'm', 'nor', 'their', 'you', \"we're\", 'what', \"should've\", 'but', 'with', 've', 'was', \"you'll\", \"doesn't\", 'for', 'don', 'doesn', 'below', 's', 'when', 'hadn', \"he'll\", 'will', 'as', 'theirs', \"he's\", 'or', 'why', 'i', 'a', 'are', 'had', \"mightn't\", 'off', 'than', 'which', 'while', 'doing', 'yours', 'over', 'an', \"they'll\", 'against', 'ain', 'couldn', 'before', \"i'd\", 'just', 'been', \"we'd\", 'does', 'hers', 'having', \"she'll\", 'our', 'here', \"you'd\", 'these', 'both', 'some', 'at', 'hasn', \"that'll\", 'has', 'its', 'your', 'so', 'yourself', \"she's\", 'mightn', 'there', 'where', 'each'}\n"
     ]
    }
   ],
   "source": [
    "print(set(nltk.corpus.stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt essential develop non precious metal based alternatives used hydrogen \n",
      "../files/input\\file2.txt electric vehicles gaining global popularity lately along efficient bat\n",
      "../files/input\\file3.txt global solar irradiation important variable used determine suitability\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "def save_data(output_directory, sequence):\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    for file, tokens in sequence:\n",
    "        file = file.replace(\"\\\\\", \"/\")\n",
    "        with open(\n",
    "            f\"{output_directory}/{file.split(\"/\")[-1]}\",\n",
    "            \"wt\",\n",
    "            encoding=\"utf-8\",\n",
    "        ) as f:\n",
    "            f.write(textwrap.fill(\" \".join(tokens), width=70))\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "filtered_sequence = remove_stopwords(filtered_sequence)\n",
    "save_data(output_directory=\"../files/output\", sequence=filtered_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file} {' '.join(text)[:70]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
